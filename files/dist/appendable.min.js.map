{
  "version": 3,
  "sources": ["../src/data-file.ts", "../src/database.ts", "../src/resolver.ts", "../src/index-file.ts", "../src/index.ts"],
  "sourcesContent": ["import { LengthIntegrityError, RangeResolver } from \"./resolver\";\n\nexport class DataFile {\n  private constructor(\n    private resolver: (start: number, end: number) => Promise<ArrayBuffer>\n  ) {}\n\n  static forUrl(url: string) {\n    return DataFile.forResolver(async ({ start, end }) => {\n      const response = await fetch(url, {\n        headers: { Range: `bytes=${start}-${end}` },\n      });\n      const totalLength = Number(\n        response.headers.get(\"Content-Range\")!.split(\"/\")[1]\n      );\n      return {\n        data: await response.arrayBuffer(),\n        totalLength: totalLength,\n      };\n    });\n  }\n\n  static forResolver(resolver: RangeResolver) {\n    return new DataFile(async (start, end) => {\n      return (\n        await resolver({\n          start,\n          end,\n        })\n      ).data;\n    });\n  }\n\n  async get(startByteOffset: number, endByteOffset: number) {\n    const data = await this.resolver(startByteOffset, endByteOffset);\n    return new TextDecoder().decode(data);\n  }\n}\n", "import { DataFile } from \"./data-file\";\nimport { IndexFile, VersionedIndexFile } from \"./index-file\";\n\ntype Schema = {\n  [key: string]: {};\n};\n\ntype WhereNode<T extends Schema> = {\n  operation: \"<\" | \"<=\" | \"==\" | \">=\" | \">\";\n  key: keyof T;\n  value: T[typeof this.key];\n};\n\ntype OrderBy<T extends Schema> = {\n  key: keyof T;\n  direction: \"ASC\" | \"DESC\";\n};\n\ntype Query<T extends Schema> = {\n  where?: WhereNode<T>[];\n  orderBy?: OrderBy<T>[];\n};\n\nfunction parseIgnoringSuffix(x: string) {\n  // TODO: implement a proper parser.\n  try {\n    return JSON.parse(x);\n  } catch (e) {\n    let m = e.message.match(/position\\s+(\\d+)/);\n    if (m) {\n      x = x.slice(0, m[1]);\n    }\n  }\n  return JSON.parse(x);\n}\n\nfunction fieldRank(token: any) {\n  if (token === null) {\n    return 1;\n  }\n  if (typeof token === \"boolean\") {\n    return 2;\n  }\n  if (typeof token === \"number\" || typeof token === \"bigint\") {\n    return 3;\n  }\n  if (typeof token === \"string\") {\n    return 4;\n  }\n  throw new Error(\"unknown type\");\n}\n\nfunction cmp(a: any, b: any) {\n  const atr = fieldRank(a);\n  const btr = fieldRank(b);\n  if (atr !== btr) {\n    return atr - btr;\n  }\n  switch (atr) {\n    case 1:\n      return 0;\n    case 2:\n      return a ? 1 : -1;\n    case 3:\n      return a - b;\n    case 4:\n      return a.localeCompare(b);\n    default:\n      throw new Error(\"unknown type\");\n  }\n}\n\nexport class Database<T extends Schema> {\n  private constructor(\n    private dataFile: DataFile,\n    private indexFile: VersionedIndexFile<T>\n  ) {}\n\n  static forDataFileAndIndexFile<T extends Schema>(\n    dataFile: DataFile,\n    indexFile: VersionedIndexFile<T>\n  ) {\n    return new Database(dataFile, indexFile);\n  }\n\n  async fields() {\n    return await this.indexFile.indexHeaders();\n  }\n\n  async *query(query: Query<T>) {\n    // verify that the query does not require a composite index\n    if (new Set((query.where ?? []).map((where) => where.key)).size > 1) {\n      throw new Error(\"composite indexes not supported... yet\");\n    }\n    // convert each of the where nodes into a range of field values.\n    const headers = await this.indexFile.indexHeaders();\n    const fieldRanges = await Promise.all(\n      (query.where ?? []).map(async ({ key, value, operation }) => {\n        const header = headers.find((header) => header.fieldName === key);\n        if (!header) {\n          throw new Error(\"field not found\");\n        }\n        let firstIndex = 0,\n          lastIndex = Number(header.indexRecordCount);\n        if (operation === \">\" || operation === \">=\" || operation === \"==\") {\n          let start = 0;\n          let end = Number(header.indexRecordCount);\n          while (start + 1 < end) {\n            const mid = Math.floor((start + end) / 2);\n            const indexRecord = await this.indexFile.indexRecord(key, mid);\n            const data = await this.dataFile.get(\n              indexRecord.fieldStartByteOffset,\n              indexRecord.fieldStartByteOffset + indexRecord.fieldLength\n            );\n            const dataFieldValue = parseIgnoringSuffix(data);\n            console.log(mid, dataFieldValue);\n            if (cmp(value, dataFieldValue) < 0) {\n              end = mid;\n            } else if (cmp(value, dataFieldValue) > 0) {\n              start = mid + 1;\n            } else if (operation === \">\") {\n              start = mid + 1;\n            } else {\n              end = mid;\n            }\n          }\n          firstIndex = end;\n        }\n        if (operation === \"<\" || operation === \"<=\" || operation === \"==\") {\n          let start = 0;\n          let end = Number(header.indexRecordCount);\n          while (start + 1 < end) {\n            const mid = Math.floor((start + end) / 2);\n            const indexRecord = await this.indexFile.indexRecord(key, mid);\n            const dataFieldValue = parseIgnoringSuffix(\n              await this.dataFile.get(\n                indexRecord.fieldStartByteOffset,\n                indexRecord.fieldStartByteOffset + indexRecord.fieldLength\n              )\n            );\n            if (cmp(value, dataFieldValue) < 0) {\n              end = mid;\n            } else if (cmp(value, dataFieldValue) > 0) {\n              start = mid + 1;\n            } else if (operation === \"<\") {\n              end = mid;\n            } else {\n              start = mid + 1;\n            }\n          }\n          lastIndex = end;\n        }\n        return [key, [firstIndex, lastIndex]] as [keyof T, [number, number]];\n      })\n    );\n    // group the field ranges by the field name and merge them into single ranges.\n    const fieldRangeMap = new Map<keyof T, [number, number]>();\n    for (const [key, value] of fieldRanges) {\n      const existing = fieldRangeMap.get(key);\n      if (existing) {\n        fieldRangeMap.set(key, [\n          Math.max(existing[0], value[0]),\n          Math.min(existing[1], value[1]),\n        ]);\n      } else {\n        fieldRangeMap.set(key, value);\n      }\n    }\n    // sort the field ranges by size.\n    const fieldRangesSorted = [...fieldRangeMap.entries()].sort(\n      (a, b) => a[1][1] - a[1][0] - (b[1][1] - b[1][0])\n    );\n    // move the order by fields to the front of the field ranges.\n    const orderByFields = (query.orderBy ?? []).map((orderBy) => orderBy.key);\n    for (const orderByField of orderByFields) {\n      const index = fieldRangesSorted.findIndex(\n        (fieldRange) => fieldRange[0] === orderByField\n      );\n      if (index >= 0) {\n        fieldRangesSorted.unshift(...fieldRangesSorted.splice(index, 1));\n      }\n    }\n    // evaluate the field ranges in order.\n    for (const [key, [start, end]] of fieldRangesSorted) {\n      // check if the iteration order should be reversed.\n      console.log(query.orderBy);\n      const orderBy = query.orderBy?.find((orderBy) => orderBy.key === key);\n      console.log(orderBy);\n      const reverse = orderBy?.direction === \"DESC\";\n      console.log(key, start, end, reverse);\n      const length = end - start;\n      for (let offset = 0; offset < length; offset++) {\n        const index = reverse ? end - offset - 1 : start + offset;\n        const indexRecord = await this.indexFile.indexRecord(key, index);\n        const dataRecord = await this.indexFile.dataRecord(\n          indexRecord.dataNumber\n        );\n        const dataFieldValue = parseIgnoringSuffix(\n          await this.dataFile.get(\n            dataRecord.startByteOffset,\n            dataRecord.endByteOffset\n          )\n        );\n        yield dataFieldValue;\n      }\n    }\n  }\n}\n", "/**\n * RangeResolver is a function that takes a range of bytes and returns a promise\n * that resolves to an ArrayBuffer containing the bytes in that range. Note that\n * the range is inclusive.\n *\n * Additionally, the RangeResolver must return a checksum which is computed from\n * the source data. This checksum is used to verify that the data has not been\n * changed between requests. The checksum can be any type, for example it is\n * valid to use the last modified timestamp of the source data or the total\n * length of the data. This checksum is passed to the RangeResolver on future\n * requests as the `checksum` argument. If it does not match the checksum when\n * reading the data, the RangeResolver should throw a LengthIntegrityError.\n *\n * @see LengthIntegrityError\n */\nexport type RangeResolver = (args: {\n  start: number;\n  end: number;\n  expectedLength?: number;\n}) => Promise<{\n  data: ArrayBuffer;\n  totalLength: number;\n}>;\n\n/**\n * LengthIntegrityError is thrown by a RangeResolver when the length argument is\n * inconsistent with the data returned. This is used to detect when the data has\n * changed between requests.\n *\n * When a LengthIntegrityError is thrown, typically the cache is evicted and the\n * query will be tried again with the exception of the data file where the error\n * is ignored due to the assumed immutability of the data file.\n *\n * @see RangeResolver\n */\nexport class LengthIntegrityError extends Error {\n  constructor() {\n    super(\"length integrity error\");\n  }\n}\n", "import { LengthIntegrityError, RangeResolver } from \"./resolver\";\n\nexport class IndexFile {\n  static async forUrl<T = any>(url: string) {\n    return await IndexFile.forResolver<T>(\n      async ({ start, end, expectedLength }) => {\n        const response = await fetch(url, {\n          headers: { Range: `bytes=${start}-${end}` },\n        });\n        const totalLength = Number(\n          response.headers.get(\"Content-Range\")!.split(\"/\")[1]\n        );\n        if (expectedLength && totalLength !== expectedLength) {\n          throw new LengthIntegrityError();\n        }\n        return {\n          data: await response.arrayBuffer(),\n          totalLength: totalLength,\n        };\n      }\n    );\n  }\n\n  static async forResolver<T = any>(\n    resolver: RangeResolver\n  ): Promise<VersionedIndexFile<T>> {\n    const response = await resolver({ start: 0, end: 0 });\n    const version = new DataView(response.data).getUint8(0);\n    switch (version) {\n      case 1:\n        return new IndexFileV1<T>(async (start, end) => {\n          return (\n            await resolver({\n              start,\n              end,\n              expectedLength: response.totalLength,\n            })\n          ).data;\n        });\n      default:\n        throw new Error(\"invalid version\");\n    }\n  }\n}\n\nfunction decodeFloatingInt16(x: number) {\n  const exponent = x >> 11;\n  const mantissa = x & 0x7ff;\n  return (1 << exponent) * mantissa + (1 << (exponent + 11)) - (1 << 11);\n}\n\nexport interface VersionedIndexFile<T> {\n  indexFileHeader(): Promise<{\n    indexLength: number;\n    dataCount: number;\n  }>;\n  indexHeaders(): Promise<\n    {\n      fieldName: string;\n      fieldType: bigint;\n      indexRecordCount: bigint;\n    }[]\n  >;\n  indexRecord(\n    field: keyof T,\n    offset: number\n  ): Promise<{\n    dataNumber: number;\n    fieldStartByteOffset: number;\n    fieldLength: number;\n  }>;\n  dataRecord(\n    offset: number\n  ): Promise<{ startByteOffset: number; endByteOffset: number }>;\n}\n\nclass IndexFileV1<T> implements VersionedIndexFile<T> {\n  private _indexFileHeader?: {\n    indexLength: number;\n    dataCount: number;\n  };\n  private _indexHeaders?: {\n    fieldName: string;\n    fieldType: bigint;\n    indexRecordCount: bigint;\n  }[];\n\n  private static INDEX_RECORD_SIZE = 18;\n\n  constructor(\n    private resolver: (start: number, end: number) => Promise<ArrayBuffer>\n  ) {}\n\n  async indexFileHeader() {\n    if (this._indexFileHeader) {\n      return this._indexFileHeader;\n    }\n    const header = new DataView(await this.resolver(1, 16));\n    this._indexFileHeader = {\n      indexLength: Number(header.getBigUint64(0)),\n      dataCount: Number(header.getBigUint64(8)),\n    };\n    return this._indexFileHeader;\n  }\n\n  async indexHeaders() {\n    if (this._indexHeaders) {\n      return this._indexHeaders;\n    }\n    const indexFileHeader = await this.indexFileHeader();\n    const buffer = await this.resolver(17, indexFileHeader.indexLength + 16);\n    const data = new DataView(buffer);\n    const headers: {\n      fieldName: string;\n      fieldType: bigint;\n      indexRecordCount: bigint;\n    }[] = [];\n    let offset = 0;\n    while (offset < indexFileHeader.indexLength) {\n      const fieldNameLength = data.getUint32(offset);\n      offset += 4;\n      const fieldName = new TextDecoder(\"utf-8\").decode(\n        buffer.slice(offset, offset + fieldNameLength)\n      );\n      offset += fieldNameLength;\n      const fieldType = data.getBigUint64(offset);\n      offset += 8;\n      const indexRecordCount = data.getBigUint64(offset);\n      offset += 8;\n      headers.push({\n        fieldName,\n        fieldType,\n        indexRecordCount,\n      });\n    }\n    if (offset !== indexFileHeader.indexLength) {\n      throw new Error(\n        `Inaccurate header read, offset = ${offset} but indexFileHeader.indexLength = ${indexFileHeader.indexLength}. This could indicate that the index file is corrupt.`\n      );\n    }\n    this._indexHeaders = headers;\n    return headers;\n  }\n\n  async indexRecord(field: keyof T, offset: number) {\n    if (offset < 0) {\n      throw new Error(\"offset out of range\");\n    }\n    const headers = await this.indexHeaders();\n    const headerIndex = headers.findIndex(\n      (header) => header.fieldName === field\n    );\n    if (headerIndex === -1) {\n      throw new Error(\"field not found\");\n    }\n    const header = headers[headerIndex];\n    if (offset >= Number(header.indexRecordCount)) {\n      throw new Error(\"offset out of range\");\n    }\n\n    const indexFileHeader = await this.indexFileHeader();\n    const indexRecordsStart = 17 + indexFileHeader.indexLength;\n    const headerOffset = headers.slice(0, headerIndex).reduce((acc, header) => {\n      return (\n        acc + Number(header.indexRecordCount) * IndexFileV1.INDEX_RECORD_SIZE\n      );\n    }, 0);\n    const recordOffset =\n      indexRecordsStart + headerOffset + offset * IndexFileV1.INDEX_RECORD_SIZE;\n    const buffer = await this.resolver(\n      recordOffset,\n      recordOffset + IndexFileV1.INDEX_RECORD_SIZE\n    );\n    const data = new DataView(buffer);\n\n    const dataNumber = data.getBigUint64(0);\n    const fieldStartByteOffset = data.getBigUint64(8);\n    const fieldLength = decodeFloatingInt16(data.getUint16(16));\n\n    return {\n      dataNumber: Number(dataNumber),\n      fieldStartByteOffset: Number(fieldStartByteOffset),\n      fieldLength: fieldLength,\n    };\n  }\n\n  async dataRecord(offset: number) {\n    if (offset < 0) {\n      throw new Error(\"offset out of range\");\n    }\n    const indexFileHeader = await this.indexFileHeader();\n    if (offset >= indexFileHeader.dataCount) {\n      throw new Error(\"offset out of range\");\n    }\n    const headers = await this.indexHeaders();\n    const indexRecordsLength = headers.reduce((acc, header) => {\n      return (\n        acc + Number(header.indexRecordCount) * IndexFileV1.INDEX_RECORD_SIZE\n      );\n    }, 0);\n    const start = 17 + indexFileHeader.indexLength + indexRecordsLength;\n    // fetch the byte offsets. if offset is 0, we can just fetch the first 8 bytes.\n    if (offset === 0) {\n      const buffer = await this.resolver(\n        start + offset * 8,\n        start + offset * 8 + 8\n      );\n      const data = new DataView(buffer);\n      const endByteOffset = data.getBigUint64(0);\n      return {\n        startByteOffset: 0,\n        endByteOffset: Number(endByteOffset),\n      };\n    }\n\n    const buffer = await this.resolver(\n      start + (offset - 1) * 8,\n      start + offset * 8 + 8\n    );\n    const data = new DataView(buffer);\n    const startByteOffset = data.getBigUint64(0);\n    const endByteOffset = data.getBigUint64(8);\n    return {\n      startByteOffset: Number(startByteOffset),\n      endByteOffset: Number(endByteOffset),\n    };\n  }\n}\n", "import { DataFile } from \"./data-file\";\nimport { Database } from \"./database\";\nimport { IndexFile } from \"./index-file\";\nimport { RangeResolver } from \"./resolver\";\n\nexport async function init(\n  dataUrl: string | RangeResolver,\n  indexUrl: string | RangeResolver\n) {\n  return Database.forDataFileAndIndexFile(\n    typeof dataUrl === \"string\"\n      ? DataFile.forUrl(dataUrl)\n      : DataFile.forResolver(dataUrl),\n    typeof indexUrl === \"string\"\n      ? await IndexFile.forUrl(indexUrl)\n      : await IndexFile.forResolver(indexUrl)\n  );\n}\n\nglobalThis.Appendable = {\n  init,\n};\n"],
  "mappings": "MAEO,IAAMA,EAAN,MAAMC,CAAS,CACZ,YACEC,EACR,CADQ,cAAAA,CACP,CAEH,OAAO,OAAOC,EAAa,CACzB,OAAOF,EAAS,YAAY,MAAO,CAAE,MAAAG,EAAO,IAAAC,CAAI,IAAM,CACpD,IAAMC,EAAW,MAAM,MAAMH,EAAK,CAChC,QAAS,CAAE,MAAO,SAASC,CAAK,IAAIC,CAAG,EAAG,CAC5C,CAAC,EACKE,EAAc,OAClBD,EAAS,QAAQ,IAAI,eAAe,EAAG,MAAM,GAAG,EAAE,CAAC,CACrD,EACA,MAAO,CACL,KAAM,MAAMA,EAAS,YAAY,EACjC,YAAaC,CACf,CACF,CAAC,CACH,CAEA,OAAO,YAAYL,EAAyB,CAC1C,OAAO,IAAID,EAAS,MAAOG,EAAOC,KAE9B,MAAMH,EAAS,CACb,MAAAE,EACA,IAAAC,CACF,CAAC,GACD,IACH,CACH,CAEA,MAAM,IAAIG,EAAyBC,EAAuB,CACxD,IAAMC,EAAO,MAAM,KAAK,SAASF,EAAiBC,CAAa,EAC/D,OAAO,IAAI,YAAY,EAAE,OAAOC,CAAI,CACtC,CACF,ECdA,SAASC,EAAoBC,EAAW,CAEtC,GAAI,CACF,OAAO,KAAK,MAAMA,CAAC,CACrB,OAAS,EAAG,CACV,IAAIC,EAAI,EAAE,QAAQ,MAAM,kBAAkB,EACtCA,IACFD,EAAIA,EAAE,MAAM,EAAGC,EAAE,CAAC,CAAC,EAEvB,CACA,OAAO,KAAK,MAAMD,CAAC,CACrB,CAEA,SAASE,EAAUC,EAAY,CAC7B,GAAIA,IAAU,KACZ,MAAO,GAET,GAAI,OAAOA,GAAU,UACnB,MAAO,GAET,GAAI,OAAOA,GAAU,UAAY,OAAOA,GAAU,SAChD,MAAO,GAET,GAAI,OAAOA,GAAU,SACnB,MAAO,GAET,MAAM,IAAI,MAAM,cAAc,CAChC,CAEA,SAASC,EAAIC,EAAQC,EAAQ,CAC3B,IAAMC,EAAML,EAAUG,CAAC,EACjBG,EAAMN,EAAUI,CAAC,EACvB,GAAIC,IAAQC,EACV,OAAOD,EAAMC,EAEf,OAAQD,EAAK,CACX,IAAK,GACH,MAAO,GACT,IAAK,GACH,OAAOF,EAAI,EAAI,GACjB,IAAK,GACH,OAAOA,EAAIC,EACb,IAAK,GACH,OAAOD,EAAE,cAAcC,CAAC,EAC1B,QACE,MAAM,IAAI,MAAM,cAAc,CAClC,CACF,CAEO,IAAMG,EAAN,MAAMC,CAA2B,CAC9B,YACEC,EACAC,EACR,CAFQ,cAAAD,EACA,eAAAC,CACP,CAEH,OAAO,wBACLD,EACAC,EACA,CACA,OAAO,IAAIF,EAASC,EAAUC,CAAS,CACzC,CAEA,MAAM,QAAS,CACb,OAAO,MAAM,KAAK,UAAU,aAAa,CAC3C,CAEA,MAAO,MAAMC,EAAiB,CAE5B,GAAI,IAAI,KAAKA,EAAM,OAAS,CAAC,GAAG,IAAKC,GAAUA,EAAM,GAAG,CAAC,EAAE,KAAO,EAChE,MAAM,IAAI,MAAM,wCAAwC,EAG1D,IAAMC,EAAU,MAAM,KAAK,UAAU,aAAa,EAC5CC,EAAc,MAAM,QAAQ,KAC/BH,EAAM,OAAS,CAAC,GAAG,IAAI,MAAO,CAAE,IAAAI,EAAK,MAAAC,EAAO,UAAAC,CAAU,IAAM,CAC3D,IAAMC,EAASL,EAAQ,KAAMK,GAAWA,EAAO,YAAcH,CAAG,EAChE,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,iBAAiB,EAEnC,IAAIC,EAAa,EACfC,EAAY,OAAOF,EAAO,gBAAgB,EAC5C,GAAID,IAAc,KAAOA,IAAc,MAAQA,IAAc,KAAM,CACjE,IAAII,EAAQ,EACRC,EAAM,OAAOJ,EAAO,gBAAgB,EACxC,KAAOG,EAAQ,EAAIC,GAAK,CACtB,IAAMC,EAAM,KAAK,OAAOF,EAAQC,GAAO,CAAC,EAClCE,EAAc,MAAM,KAAK,UAAU,YAAYT,EAAKQ,CAAG,EACvDE,EAAO,MAAM,KAAK,SAAS,IAC/BD,EAAY,qBACZA,EAAY,qBAAuBA,EAAY,WACjD,EACME,EAAiB7B,EAAoB4B,CAAI,EAC/C,QAAQ,IAAIF,EAAKG,CAAc,EAC3BxB,EAAIc,EAAOU,CAAc,EAAI,EAC/BJ,EAAMC,EACGrB,EAAIc,EAAOU,CAAc,EAAI,GAE7BT,IAAc,IADvBI,EAAQE,EAAM,EAIdD,EAAMC,CAEV,CACAJ,EAAaG,CACf,CACA,GAAIL,IAAc,KAAOA,IAAc,MAAQA,IAAc,KAAM,CACjE,IAAII,EAAQ,EACRC,EAAM,OAAOJ,EAAO,gBAAgB,EACxC,KAAOG,EAAQ,EAAIC,GAAK,CACtB,IAAMC,EAAM,KAAK,OAAOF,EAAQC,GAAO,CAAC,EAClCE,EAAc,MAAM,KAAK,UAAU,YAAYT,EAAKQ,CAAG,EACvDG,EAAiB7B,EACrB,MAAM,KAAK,SAAS,IAClB2B,EAAY,qBACZA,EAAY,qBAAuBA,EAAY,WACjD,CACF,EACItB,EAAIc,EAAOU,CAAc,EAAI,EAC/BJ,EAAMC,EACGrB,EAAIc,EAAOU,CAAc,EAAI,EACtCL,EAAQE,EAAM,EACLN,IAAc,IACvBK,EAAMC,EAENF,EAAQE,EAAM,CAElB,CACAH,EAAYE,CACd,CACA,MAAO,CAACP,EAAK,CAACI,EAAYC,CAAS,CAAC,CACtC,CAAC,CACH,EAEMO,EAAgB,IAAI,IAC1B,OAAW,CAACZ,EAAKC,CAAK,IAAKF,EAAa,CACtC,IAAMc,EAAWD,EAAc,IAAIZ,CAAG,EAClCa,EACFD,EAAc,IAAIZ,EAAK,CACrB,KAAK,IAAIa,EAAS,CAAC,EAAGZ,EAAM,CAAC,CAAC,EAC9B,KAAK,IAAIY,EAAS,CAAC,EAAGZ,EAAM,CAAC,CAAC,CAChC,CAAC,EAEDW,EAAc,IAAIZ,EAAKC,CAAK,CAEhC,CAEA,IAAMa,EAAoB,CAAC,GAAGF,EAAc,QAAQ,CAAC,EAAE,KACrD,CAACxB,EAAGC,IAAMD,EAAE,CAAC,EAAE,CAAC,EAAIA,EAAE,CAAC,EAAE,CAAC,GAAKC,EAAE,CAAC,EAAE,CAAC,EAAIA,EAAE,CAAC,EAAE,CAAC,EACjD,EAEM0B,GAAiBnB,EAAM,SAAW,CAAC,GAAG,IAAKoB,GAAYA,EAAQ,GAAG,EACxE,QAAWC,KAAgBF,EAAe,CACxC,IAAMG,EAAQJ,EAAkB,UAC7BK,GAAeA,EAAW,CAAC,IAAMF,CACpC,EACIC,GAAS,GACXJ,EAAkB,QAAQ,GAAGA,EAAkB,OAAOI,EAAO,CAAC,CAAC,CAEnE,CAEA,OAAW,CAAClB,EAAK,CAACM,EAAOC,CAAG,CAAC,IAAKO,EAAmB,CAEnD,QAAQ,IAAIlB,EAAM,OAAO,EACzB,IAAMoB,EAAUpB,EAAM,SAAS,KAAMoB,GAAYA,EAAQ,MAAQhB,CAAG,EACpE,QAAQ,IAAIgB,CAAO,EACnB,IAAMI,EAAUJ,GAAS,YAAc,OACvC,QAAQ,IAAIhB,EAAKM,EAAOC,EAAKa,CAAO,EACpC,IAAMC,EAASd,EAAMD,EACrB,QAASgB,EAAS,EAAGA,EAASD,EAAQC,IAAU,CAC9C,IAAMJ,EAAQE,EAAUb,EAAMe,EAAS,EAAIhB,EAAQgB,EAC7Cb,EAAc,MAAM,KAAK,UAAU,YAAYT,EAAKkB,CAAK,EACzDK,EAAa,MAAM,KAAK,UAAU,WACtCd,EAAY,UACd,EAOA,MANuB3B,EACrB,MAAM,KAAK,SAAS,IAClByC,EAAW,gBACXA,EAAW,aACb,CACF,CAEF,CACF,CACF,CACF,EC5KO,IAAMC,EAAN,cAAmC,KAAM,CAC9C,aAAc,CACZ,MAAM,wBAAwB,CAChC,CACF,ECrCO,IAAMC,EAAN,MAAMC,CAAU,CACrB,aAAa,OAAgBC,EAAa,CACxC,OAAO,MAAMD,EAAU,YACrB,MAAO,CAAE,MAAAE,EAAO,IAAAC,EAAK,eAAAC,CAAe,IAAM,CACxC,IAAMC,EAAW,MAAM,MAAMJ,EAAK,CAChC,QAAS,CAAE,MAAO,SAASC,CAAK,IAAIC,CAAG,EAAG,CAC5C,CAAC,EACKG,EAAc,OAClBD,EAAS,QAAQ,IAAI,eAAe,EAAG,MAAM,GAAG,EAAE,CAAC,CACrD,EACA,GAAID,GAAkBE,IAAgBF,EACpC,MAAM,IAAIG,EAEZ,MAAO,CACL,KAAM,MAAMF,EAAS,YAAY,EACjC,YAAaC,CACf,CACF,CACF,CACF,CAEA,aAAa,YACXE,EACgC,CAChC,IAAMH,EAAW,MAAMG,EAAS,CAAE,MAAO,EAAG,IAAK,CAAE,CAAC,EAEpD,OADgB,IAAI,SAASH,EAAS,IAAI,EAAE,SAAS,CAAC,EACrC,CACf,IAAK,GACH,OAAO,IAAII,EAAe,MAAOP,EAAOC,KAEpC,MAAMK,EAAS,CACb,MAAAN,EACA,IAAAC,EACA,eAAgBE,EAAS,WAC3B,CAAC,GACD,IACH,EACH,QACE,MAAM,IAAI,MAAM,iBAAiB,CACrC,CACF,CACF,EAEA,SAASK,EAAoBC,EAAW,CACtC,IAAMC,EAAWD,GAAK,GAChBE,EAAWF,EAAI,KACrB,OAAQ,GAAKC,GAAYC,GAAY,GAAMD,EAAW,IAAQ,IAChE,CA2BA,IAAMH,EAAN,MAAMK,CAAgD,CAapD,YACUN,EACR,CADQ,cAAAA,CACP,CAdK,iBAIA,cAMR,OAAe,kBAAoB,GAMnC,MAAM,iBAAkB,CACtB,GAAI,KAAK,iBACP,OAAO,KAAK,iBAEd,IAAMO,EAAS,IAAI,SAAS,MAAM,KAAK,SAAS,EAAG,EAAE,CAAC,EACtD,YAAK,iBAAmB,CACtB,YAAa,OAAOA,EAAO,aAAa,CAAC,CAAC,EAC1C,UAAW,OAAOA,EAAO,aAAa,CAAC,CAAC,CAC1C,EACO,KAAK,gBACd,CAEA,MAAM,cAAe,CACnB,GAAI,KAAK,cACP,OAAO,KAAK,cAEd,IAAMC,EAAkB,MAAM,KAAK,gBAAgB,EAC7CC,EAAS,MAAM,KAAK,SAAS,GAAID,EAAgB,YAAc,EAAE,EACjEE,EAAO,IAAI,SAASD,CAAM,EAC1BE,EAIA,CAAC,EACHC,EAAS,EACb,KAAOA,EAASJ,EAAgB,aAAa,CAC3C,IAAMK,EAAkBH,EAAK,UAAUE,CAAM,EAC7CA,GAAU,EACV,IAAME,EAAY,IAAI,YAAY,OAAO,EAAE,OACzCL,EAAO,MAAMG,EAAQA,EAASC,CAAe,CAC/C,EACAD,GAAUC,EACV,IAAME,EAAYL,EAAK,aAAaE,CAAM,EAC1CA,GAAU,EACV,IAAMI,EAAmBN,EAAK,aAAaE,CAAM,EACjDA,GAAU,EACVD,EAAQ,KAAK,CACX,UAAAG,EACA,UAAAC,EACA,iBAAAC,CACF,CAAC,CACH,CACA,GAAIJ,IAAWJ,EAAgB,YAC7B,MAAM,IAAI,MACR,oCAAoCI,CAAM,sCAAsCJ,EAAgB,WAAW,uDAC7G,EAEF,YAAK,cAAgBG,EACdA,CACT,CAEA,MAAM,YAAYM,EAAgBL,EAAgB,CAChD,GAAIA,EAAS,EACX,MAAM,IAAI,MAAM,qBAAqB,EAEvC,IAAMD,EAAU,MAAM,KAAK,aAAa,EAClCO,EAAcP,EAAQ,UACzBJ,GAAWA,EAAO,YAAcU,CACnC,EACA,GAAIC,IAAgB,GAClB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,IAAMX,EAASI,EAAQO,CAAW,EAClC,GAAIN,GAAU,OAAOL,EAAO,gBAAgB,EAC1C,MAAM,IAAI,MAAM,qBAAqB,EAIvC,IAAMY,EAAoB,IADF,MAAM,KAAK,gBAAgB,GACJ,YACzCC,EAAeT,EAAQ,MAAM,EAAGO,CAAW,EAAE,OAAO,CAACG,EAAKd,IAE5Dc,EAAM,OAAOd,EAAO,gBAAgB,EAAID,EAAY,kBAErD,CAAC,EACEgB,EACJH,EAAoBC,EAAeR,EAASN,EAAY,kBACpDG,EAAS,MAAM,KAAK,SACxBa,EACAA,EAAehB,EAAY,iBAC7B,EACMI,EAAO,IAAI,SAASD,CAAM,EAE1Bc,EAAab,EAAK,aAAa,CAAC,EAChCc,EAAuBd,EAAK,aAAa,CAAC,EAC1Ce,EAAcvB,EAAoBQ,EAAK,UAAU,EAAE,CAAC,EAE1D,MAAO,CACL,WAAY,OAAOa,CAAU,EAC7B,qBAAsB,OAAOC,CAAoB,EACjD,YAAaC,CACf,CACF,CAEA,MAAM,WAAWb,EAAgB,CAC/B,GAAIA,EAAS,EACX,MAAM,IAAI,MAAM,qBAAqB,EAEvC,IAAMJ,EAAkB,MAAM,KAAK,gBAAgB,EACnD,GAAII,GAAUJ,EAAgB,UAC5B,MAAM,IAAI,MAAM,qBAAqB,EAGvC,IAAMkB,GADU,MAAM,KAAK,aAAa,GACL,OAAO,CAACL,EAAKd,IAE5Cc,EAAM,OAAOd,EAAO,gBAAgB,EAAID,EAAY,kBAErD,CAAC,EACEZ,EAAQ,GAAKc,EAAgB,YAAckB,EAEjD,GAAId,IAAW,EAAG,CAChB,IAAMH,EAAS,MAAM,KAAK,SACxBf,EAAQkB,EAAS,EACjBlB,EAAQkB,EAAS,EAAI,CACvB,EAEMe,EADO,IAAI,SAASlB,CAAM,EACL,aAAa,CAAC,EACzC,MAAO,CACL,gBAAiB,EACjB,cAAe,OAAOkB,CAAa,CACrC,CACF,CAEA,IAAMlB,EAAS,MAAM,KAAK,SACxBf,GAASkB,EAAS,GAAK,EACvBlB,EAAQkB,EAAS,EAAI,CACvB,EACMF,EAAO,IAAI,SAASD,CAAM,EAC1BmB,EAAkBlB,EAAK,aAAa,CAAC,EACrCiB,EAAgBjB,EAAK,aAAa,CAAC,EACzC,MAAO,CACL,gBAAiB,OAAOkB,CAAe,EACvC,cAAe,OAAOD,CAAa,CACrC,CACF,CACF,EC9NA,eAAsBE,EACpBC,EACAC,EACA,CACA,OAAOC,EAAS,wBACd,OAAOF,GAAY,SACfG,EAAS,OAAOH,CAAO,EACvBG,EAAS,YAAYH,CAAO,EAChC,OAAOC,GAAa,SAChB,MAAMG,EAAU,OAAOH,CAAQ,EAC/B,MAAMG,EAAU,YAAYH,CAAQ,CAC1C,CACF,CAEA,WAAW,WAAa,CACtB,KAAAF,CACF",
  "names": ["DataFile", "_DataFile", "resolver", "url", "start", "end", "response", "totalLength", "startByteOffset", "endByteOffset", "data", "parseIgnoringSuffix", "x", "m", "fieldRank", "token", "cmp", "a", "b", "atr", "btr", "Database", "_Database", "dataFile", "indexFile", "query", "where", "headers", "fieldRanges", "key", "value", "operation", "header", "firstIndex", "lastIndex", "start", "end", "mid", "indexRecord", "data", "dataFieldValue", "fieldRangeMap", "existing", "fieldRangesSorted", "orderByFields", "orderBy", "orderByField", "index", "fieldRange", "reverse", "length", "offset", "dataRecord", "LengthIntegrityError", "IndexFile", "_IndexFile", "url", "start", "end", "expectedLength", "response", "totalLength", "LengthIntegrityError", "resolver", "IndexFileV1", "decodeFloatingInt16", "x", "exponent", "mantissa", "_IndexFileV1", "header", "indexFileHeader", "buffer", "data", "headers", "offset", "fieldNameLength", "fieldName", "fieldType", "indexRecordCount", "field", "headerIndex", "indexRecordsStart", "headerOffset", "acc", "recordOffset", "dataNumber", "fieldStartByteOffset", "fieldLength", "indexRecordsLength", "endByteOffset", "startByteOffset", "init", "dataUrl", "indexUrl", "Database", "DataFile", "IndexFile"]
}
